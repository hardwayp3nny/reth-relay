#![warn(unused_crate_dependencies)]

use chain_cfg::{boot_nodes, head, polygon_chain_spec};
use alloy_consensus::transaction::Transaction as _;
use reth_discv4::{Discv4ConfigBuilder, NatResolver};
use reth_ethereum::network::{
    api::events::SessionInfo, config::NetworkMode, NetworkConfig, NetworkEvent,
    NetworkEventListenerProvider, NetworkManager,
};
use reth_ethereum::network::transactions::NetworkTransactionEvent;
use reth_tracing::{
    tracing::info, tracing_subscriber::filter::LevelFilter, LayerInfo, LogFormat, RethTracer,
    Tracer,
};
use once_cell::sync::Lazy;
use std::collections::HashMap;
use chrono::Local;
use reth_network::PeerRequest;
use tokio::sync::Semaphore;
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::time::Instant;
use parking_lot::RwLock;
use std::fs::OpenOptions;
use std::io::Write;
use secp256k1::{rand, SecretKey};
use std::{
    net::{Ipv4Addr, SocketAddr},
    time::Duration,
};
use tokio_stream::StreamExt;
use reth_network_types::{PeersConfig, SessionsConfig};
use std::path::Path;

pub mod chain_cfg;
mod analysis;
mod redis_manager;
mod redis_async;

// æ€§èƒ½ç›‘æ§ç»“æ„
#[derive(Debug, Default)]
struct PerformanceMetrics {
    tx_processed: AtomicU64,
    ctf_decoded: AtomicU64,
    avg_decode_time_ns: AtomicU64,
    avg_redis_time_ns: AtomicU64,
    memory_usage_mb: AtomicUsize,
    last_batch_size: AtomicUsize,
    blocked_time_ns: AtomicU64,
}

static PERF_METRICS: Lazy<Arc<PerformanceMetrics>> = Lazy::new(|| Arc::new(PerformanceMetrics::default()));

// é¢„è®¡ç®—çš„ABIè§£ç å™¨ç»“æ„
struct PrecomputedDecoder {
    method_name: String,
    function: ethers_core::abi::Function,
}

type DecoderMap = HashMap<[u8; 4], PrecomputedDecoder>;

// å†…å­˜ä¼˜åŒ–ï¼šå­—ç¬¦ä¸²ç¼“å†²æ± 
struct StringBufferPool {
    pool: RwLock<Vec<String>>,
    max_size: usize,
}

impl StringBufferPool {
    fn new(max_size: usize) -> Self {
        Self {
            pool: RwLock::new(Vec::with_capacity(max_size)),
            max_size,
        }
    }
    
    fn get_buffer(&self) -> String {
        if let Some(mut buffer) = self.pool.write().pop() {
            buffer.clear();
            buffer
        } else {
            String::with_capacity(256) // é¢„åˆ†é…256å­—èŠ‚
        }
    }
    
    fn return_buffer(&self, mut buffer: String) {
        if buffer.capacity() < 1024 { // åªå›æ”¶å°ç¼“å†²åŒº
            buffer.clear();
            let mut pool = self.pool.write();
            if pool.len() < self.max_size {
                pool.push(buffer);
            }
        }
    }
}

static STRING_POOL: Lazy<StringBufferPool> = Lazy::new(|| StringBufferPool::new(100));

fn persist_session_established(info: &SessionInfo) {
    const FILE: &str = concat!(env!("CARGO_MANIFEST_DIR"), "/logs/session_established.log");
    if let Some(dir) = Path::new(FILE).parent() {
        let _ = std::fs::create_dir_all(dir);
    }
    if let Ok(mut f) = OpenOptions::new().create(true).append(true).open(FILE) {
        let ts = Local::now().format("%Y-%m-%d %H:%M:%S%.6f");
        let line = format!(
            "ts_local={} peer_id={} client={} chain={:?} version={:?}\n",
            ts, info.peer_id, info.client_version, info.status.chain, info.version
        );
        let _ = f.write_all(line.as_bytes());
    }
}

// ç§»é™¤mempoolæ–‡ä»¶æŒä¹…åŒ–ï¼Œæ”¹ç”¨Redis

// ç§»é™¤tx_analysisæ–‡ä»¶æŒä¹…åŒ–ï¼Œæ”¹ç”¨Redis

// ç§»é™¤ctf_txæ–‡ä»¶æŒä¹…åŒ–ï¼Œæ”¹ç”¨Redis

// ä¼˜åŒ–ï¼šé¢„è®¡ç®—å®Œæ•´çš„è§£ç å™¨æ˜ å°„ï¼ˆåŒ…å«å‡½æ•°å¯¹è±¡ï¼‰
fn build_decoder_map(abi_json_str: &str) -> DecoderMap {
    use sha3::{Digest, Keccak256};
    use serde_json::Value;

    fn canonical_type(p: &Value) -> Option<String> {
        let ty = p.get("type")?.as_str()?;
        if let Some(rest) = ty.strip_prefix("tuple") {
            let comps = p.get("components")?.as_array()?;
            let inner: Vec<String> = comps.iter().map(|c| canonical_type(c)).collect::<Option<Vec<_>>>()?;
            Some(format!("({}){}", inner.join(","), rest))
        } else {
            Some(ty.to_string())
        }
    }

    let v: serde_json::Value = serde_json::from_str(abi_json_str).expect("abi json");
    let arr = v.as_array().expect("abi array");
    let mut map: DecoderMap = HashMap::with_capacity(arr.len()); // é¢„åˆ†é…å®¹é‡
    
    for item in arr {
        if item.get("type").and_then(|t| t.as_str()) == Some("function") {
            let name = match item.get("name").and_then(|n| n.as_str()) { 
                Some(n) => n.to_string(), 
                None => continue 
            };
            
            let inputs = item.get("inputs").and_then(|i| i.as_array()).cloned().unwrap_or_default();
            let mut tys: Vec<String> = Vec::with_capacity(inputs.len());
            for inp in &inputs {
                if let Some(ct) = canonical_type(inp) { 
                    tys.push(ct); 
                } else { 
                    tys.push(String::from("unknown")); 
                }
            }
            
            let sig = format!("{}({})", name, tys.join(","));
            let mut hasher = Keccak256::new();
            hasher.update(sig.as_bytes());
            let out = hasher.finalize();
            let selector = [out[0], out[1], out[2], out[3]];
            
            // é¢„æ„å»ºethers Functionå¯¹è±¡
            if let Ok(function) = serde_json::from_value::<ethers_core::abi::Function>(item.clone()) {
                map.insert(selector, PrecomputedDecoder {
                    method_name: name,
                    function,
                });
            }
        }
    }
    map
}

fn build_method_map(abi_json_str: &str) -> HashMap<[u8;4], String> {
    build_decoder_map(abi_json_str).into_iter()
        .map(|(k, v)| (k, v.method_name))
        .collect()
}

// åŸæœ‰çš„æ–¹æ³•åæ˜ å°„ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
static CTF_METHODS: Lazy<HashMap<[u8;4], String>> = Lazy::new(|| build_method_map(include_str!("../data/ctf_abi.json")));
static NEGRISK_METHODS: Lazy<HashMap<[u8;4], String>> = Lazy::new(|| build_method_map(include_str!("../data/negrisk_abi.json")));

// æ–°çš„é¢„è®¡ç®—è§£ç å™¨ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰
static CTF_DECODERS: Lazy<DecoderMap> = Lazy::new(|| build_decoder_map(include_str!("../data/ctf_abi.json")));
static NEGRISK_DECODERS: Lazy<DecoderMap> = Lazy::new(|| build_decoder_map(include_str!("../data/negrisk_abi.json")));

fn decode_method_from_map(method_id: &[u8], map: &HashMap<[u8;4], String>) -> Option<String> {
    if method_id.len() < 4 { return None; }
    let key = [method_id[0], method_id[1], method_id[2], method_id[3]];
    map.get(&key).cloned()
}

// æé€Ÿä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨é¢„è®¡ç®—çš„è§£ç å™¨ï¼Œé¿å…è¿è¡Œæ—¶è§£æ
fn decode_ctf_like_calldata_fast(to: alloy_primitives::Address, calldata: &[u8]) -> Option<serde_json::Value> {
    if calldata.len() < 4 { return None; }
    
    let sel = [calldata[0], calldata[1], calldata[2], calldata[3]];
    let decoder = if to == alloy_primitives::address!("0x56C79347e95530c01A2FC76E732f9566dA16E113") {
        CTF_DECODERS.get(&sel)?
    } else if to == alloy_primitives::address!("0x78769D50Be1763ed1CA0D5E878D93f05aabff29e") {
        NEGRISK_DECODERS.get(&sel)?
    } else { 
        return None; 
    };

    let args_bytes = &calldata[4..];
    // ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„å‡½æ•°å¯¹è±¡ï¼Œæ— éœ€è¿è¡Œæ—¶åˆ›å»º
    let params = decoder.function.decode_input(args_bytes).ok()?;
    Some(function_tokens_to_json_ethers_fast(&decoder.method_name, &params))
}

// ä¿æŒå‘åå…¼å®¹çš„æ…¢é€Ÿç‰ˆæœ¬
fn decode_ctf_like_calldata(to: alloy_primitives::Address, calldata: &[u8]) -> Option<serde_json::Value> {
    decode_ctf_like_calldata_fast(to, calldata)
}

fn find_function_by_selector(abi_str: &str, sel: &[u8;4]) -> Option<alloy_json_abi::Function> {
    let v: serde_json::Value = serde_json::from_str(abi_str).ok()?;
    let arr = v.as_array()?;
    for item in arr {
        if item.get("type").and_then(|t| t.as_str()) == Some("function") {
            // é‡å»º selector
            use sha3::{Digest, Keccak256};
            let name = item.get("name")?.as_str()?;
            let inputs = item.get("inputs")?.as_array()?.clone();
            fn canonical_type(p: &serde_json::Value) -> Option<String> {
                let ty = p.get("type")?.as_str()?;
                if let Some(rest) = ty.strip_prefix("tuple") {
                    let comps = p.get("components")?.as_array()?;
                    let inner: Vec<String> = comps.iter().map(|c| canonical_type(c)).collect::<Option<Vec<_>>>()?;
                    Some(format!("({}){}", inner.join(","), rest))
                } else { Some(ty.to_string()) }
            }
            let mut tys = Vec::with_capacity(inputs.len());
            for inp in &inputs { tys.push(canonical_type(inp)?); }
            let sig = format!("{}({})", name, tys.join(","));
            let mut h = Keccak256::new(); h.update(sig.as_bytes()); let out = h.finalize();
            if &out[..4] == sel {
                // ç›´æ¥ååºåˆ—åŒ–ä¸º Function ä»¥ä¾¿ decode
                return serde_json::from_value(item.clone()).ok();
            }
        }
    }
    None
}

// ä¼˜åŒ–ç‰ˆæœ¬ï¼šå‡å°‘å­—ç¬¦ä¸²åˆ†é…ï¼Œä½¿ç”¨é¢„åˆ†é…ç¼“å†²åŒº
fn function_tokens_to_json_ethers_fast(name: &str, tokens: &[ethers_core::abi::Token]) -> serde_json::Value {
    use ethers_core::abi::Token as T;
    
    // é¢„åˆ†é…å®¹é‡é¿å…é‡å¤åˆ†é…
    let mut params = Vec::with_capacity(tokens.len());
    
    for token in tokens {
        let value = match token {
            T::Address(a) => {
                // ä½¿ç”¨ç¼“å†²æ± å‡å°‘åˆ†é…
                let mut addr_str = STRING_POOL.get_buffer();
                addr_str.push_str("0x");
                addr_str.push_str(&format!("{:x}", a));
                let result = serde_json::Value::String(addr_str.clone());
                STRING_POOL.return_buffer(addr_str);
                result
            },
            T::Uint(u) => serde_json::Value::String(u.to_string()),
            T::Int(i) => serde_json::Value::String(i.to_string()),
            T::Bool(b) => serde_json::Value::Bool(*b),
            T::Bytes(b) => {
                let mut hex_str = STRING_POOL.get_buffer();
                hex_str.reserve(2 + b.len() * 2);
                hex_str.push_str("0x");
                hex_str.push_str(&hex::encode(b));
                let result = serde_json::Value::String(hex_str.clone());
                STRING_POOL.return_buffer(hex_str);
                result
            },
            T::String(s) => serde_json::Value::String(s.clone()),
            T::FixedBytes(b) => {
                let mut hex_str = STRING_POOL.get_buffer();
                hex_str.reserve(2 + b.len() * 2);
                hex_str.push_str("0x");
                hex_str.push_str(&hex::encode(b));
                let result = serde_json::Value::String(hex_str.clone());
                STRING_POOL.return_buffer(hex_str);
                result
            },
            T::Array(v) => {
                let nested: Vec<serde_json::Value> = v.iter().map(|t| tok_to_val_recursive(t)).collect();
                serde_json::Value::Array(nested)
            },
            T::FixedArray(v) => {
                let nested: Vec<serde_json::Value> = v.iter().map(|t| tok_to_val_recursive(t)).collect();
                serde_json::Value::Array(nested)
            },
            T::Tuple(v) => {
                let nested: Vec<serde_json::Value> = v.iter().map(|t| tok_to_val_recursive(t)).collect();
                serde_json::Value::Array(nested)
            },
        };
        params.push(value);
    }
    
    // ç›´æ¥æ„å»ºValueè€Œä¸æ˜¯ä½¿ç”¨json!å®
    let mut result = serde_json::Map::with_capacity(2);
    result.insert("method".to_string(), serde_json::Value::String(name.to_string()));
    result.insert("args".to_string(), serde_json::Value::Array(params));
    serde_json::Value::Object(result)
}

// é€’å½’è¾…åŠ©å‡½æ•°ï¼Œå¤„ç†åµŒå¥—ç»“æ„
fn tok_to_val_recursive(t: &ethers_core::abi::Token) -> serde_json::Value {
    use ethers_core::abi::Token as T;
    match t {
        T::Address(a) => serde_json::json!(format!("0x{:x}", a)),
        T::Uint(u) => serde_json::json!(u.to_string()),
        T::Int(i) => serde_json::json!(i.to_string()),
        T::Bool(b) => serde_json::json!(b),
        T::Bytes(b) => serde_json::json!(format!("0x{}", hex::encode(b))),
        T::String(s) => serde_json::json!(s),
        T::FixedBytes(b) => serde_json::json!(format!("0x{}", hex::encode(b))),
        T::Array(v) => serde_json::Value::Array(v.iter().map(tok_to_val_recursive).collect()),
        T::FixedArray(v) => serde_json::Value::Array(v.iter().map(tok_to_val_recursive).collect()),
        T::Tuple(v) => serde_json::Value::Array(v.iter().map(tok_to_val_recursive).collect()),
    }
}

// ä¿æŒå‘åå…¼å®¹
fn function_tokens_to_json_ethers(name: &str, tokens: &[ethers_core::abi::Token]) -> serde_json::Value {
    function_tokens_to_json_ethers_fast(name, tokens)
}

// è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨é‡ï¼ˆè¿‘ä¼¼ï¼‰
fn get_memory_usage_mb() -> usize {
    // ç®€å•çš„å†…å­˜ä¼°ç®—ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒå¯ä»¥ä½¿ç”¨æ›´ç²¾ç¡®çš„æ–¹æ³•
    let usage = std::process::Command::new("ps")
        .args(["-o", "rss=", "-p", &std::process::id().to_string()])
        .output();
    
    if let Ok(output) = usage {
        if let Ok(output_str) = std::str::from_utf8(&output.stdout) {
            if let Ok(kb) = output_str.trim().parse::<usize>() {
                return kb / 1024; // è½¬æ¢ä¸ºMB
            }
        }
    }
    0 // å¤±è´¥æ—¶è¿”å›0
}

// æ€§èƒ½ç›‘æ§å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰
async fn start_performance_monitor() {
    let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(5)); // æ›´é¢‘ç¹çš„ç›‘æ§
    let mut last_tx_count = 0u64;
    let mut last_ctf_count = 0u64;
    
    loop {
        interval.tick().await;
        let metrics = &PERF_METRICS;
        
        let tx_count = metrics.tx_processed.load(Ordering::Relaxed);
        let ctf_count = metrics.ctf_decoded.load(Ordering::Relaxed);
        let avg_decode_ns = metrics.avg_decode_time_ns.load(Ordering::Relaxed);
        let _avg_redis_ns = metrics.avg_redis_time_ns.load(Ordering::Relaxed);
        let _last_batch = metrics.last_batch_size.load(Ordering::Relaxed);
        let blocked_ns = metrics.blocked_time_ns.load(Ordering::Relaxed);
        
        // è®¡ç®—é€Ÿç‡
        let tx_rate = (tx_count - last_tx_count) / 5; // æ¯ç§’äº¤æ˜“æ•°
        let ctf_rate = (ctf_count - last_ctf_count) / 5; // æ¯ç§’CTFè§£ç æ•°
        
        // è·å–å†…å­˜ä½¿ç”¨
        let memory_mb = get_memory_usage_mb();
        metrics.memory_usage_mb.store(memory_mb, Ordering::Relaxed);
        
        info!(
            "ğŸš€ æé€Ÿæ€§èƒ½ç›‘æ§ | TX: {} (+{}/s) | CTF: {} (+{}/s) | è§£ç : {}Î¼s | å†…å­˜: {}MB | é˜»å¡: {}Î¼s",
            tx_count,
            tx_rate,
            ctf_count,
            ctf_rate,
            avg_decode_ns / 1000,
            memory_mb,
            blocked_ns / 1000
        );
        
        // æ€§èƒ½å‘Šè­¦ç³»ç»Ÿ
        if blocked_ns > 50_000_000 {
            eprintln!("ğŸ”´ ä¸¥é‡é˜»å¡: {}ms è¶…è¿‡50msé˜ˆå€¼!", blocked_ns / 1_000_000);
        } else if blocked_ns > 20_000_000 {
            eprintln!("ğŸŸ¡ è½»å¾®é˜»å¡: {}ms éœ€è¦å…³æ³¨", blocked_ns / 1_000_000);
        }
        
        if memory_mb > 500 {
            eprintln!("ğŸŸ¡ å†…å­˜ä½¿ç”¨è¿‡é«˜: {}MB", memory_mb);
        }
        
        if avg_decode_ns > 100_000_000 { // 100ms
            eprintln!("ğŸ”´ è§£ç æ€§èƒ½ä¸‹é™: {}ms è¿‡æ…¢", avg_decode_ns / 1_000_000);
        }
        
        // æ›´æ–°å†å²æ•°æ®
        last_tx_count = tx_count;
        last_ctf_count = ctf_count;
        
        // é‡ç½®å‘¨æœŸæ€§ç»Ÿè®¡
        metrics.blocked_time_ns.store(0, Ordering::Relaxed);
    }
}

// è®°å½•é˜»å¡æ—¶é—´çš„å®
macro_rules! measure_blocking {
    ($metrics:expr, $block:expr) => {{
        let start = Instant::now();
        let result = $block;
        let elapsed = start.elapsed().as_nanos() as u64;
        $metrics.blocked_time_ns.fetch_add(elapsed, Ordering::Relaxed);
        result
    }};
}

#[tokio::main]
async fn main() {
    // å¯åŠ¨æ€§èƒ½ç›‘æ§
    tokio::spawn(start_performance_monitor());
    
    // åˆå§‹åŒ–Rediså¼‚æ­¥å¤„ç†å™¨
    if let Err(e) = redis_async::init_redis_async().await {
        eprintln!("Failed to initialize Redis async processor: {}", e);
        std::process::exit(1);
    }
    info!("Rediså¼‚æ­¥å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ");
    info!("ğŸ¯ æé€Ÿä¼˜åŒ–ç‰ˆæœ¬å·²å¯åŠ¨ - ABIé¢„è®¡ç®— + æ€§èƒ½ç›‘æ§");
    info!("ğŸš€ ä¼˜åŒ–ç‰¹æ€§:");
    info!("  âœ… é¢„è®¡ç®—ABIè§£ç å™¨ (10x+ æ€§èƒ½æå‡)");
    info!("  âœ… 15ms Redisæ‰¹å¤„ç† (vs 100ms)");
    info!("  âœ… å¹¶è¡ŒCTFå¤„ç†");
    info!("  âœ… å­—ç¬¦ä¸²ç¼“å†²æ± ");
    info!("  âœ… å®æ—¶æ€§èƒ½ç›‘æ§");
    info!("  âœ… æ™ºèƒ½é˜»å¡æ£€æµ‹");
    // The ECDSA private key used to create our enode identifier.
    let secret_key = SecretKey::new(&mut rand::thread_rng());

    let _ = RethTracer::new()
        .with_stdout(LayerInfo::new(
            LogFormat::Terminal,
            LevelFilter::INFO.to_string(),
            "".to_string(),
            Some("always".to_string()),
        ))
        .init();

    // The local address we want to bind to (use env P2P_PORT or 0 for ephemeral port)
    let port: u16 = std::env::var("P2P_PORT").ok().and_then(|s| s.parse().ok()).unwrap_or(0);
    let local_addr = SocketAddr::new(Ipv4Addr::UNSPECIFIED.into(), port);

    // The network configuration with aggressive peers/session tuning
    let peers_cfg = PeersConfig::default()
        .with_max_outbound(200)
        .with_max_inbound(200)
        .with_max_concurrent_dials(200)
        .with_refill_slots_interval(Duration::from_millis(1500));

    let mut sessions_cfg = SessionsConfig::default()
        .with_session_event_buffer(8192)
        .with_upscaled_event_buffer(400);
    sessions_cfg.limits = sessions_cfg
        .limits
        .with_max_pending_outbound(400)
        .with_max_established_outbound(200)
        .with_max_established_inbound(200);

    let net_cfg = NetworkConfig::builder(secret_key)
        .set_head(head())
        .network_mode(NetworkMode::Work)
        .listener_addr(local_addr)
        .peer_config(peers_cfg)
        .sessions_config(sessions_cfg)
        .external_ip_resolver(NatResolver::default())
        .build_with_noop_provider(polygon_chain_spec());

    // æ‰“å° forkid ä»¥ä¾¿æ ¸å¯¹é“¾é…ç½®æ˜¯å¦ä¸ä¸»ç½‘ä¸€è‡´
    let chainspec = polygon_chain_spec();
    let fork_id = chainspec.fork_id(&head());
    info!(?fork_id, "computed forkid for polygon mainnet");

    // Set Discv4 lookup more aggressive
    let mut discv4_cfg = Discv4ConfigBuilder::default();
    let interval = Duration::from_millis(250);
    let boot = boot_nodes();
    info!(count = boot.len(), "bootnodes loaded");
    for (i, n) in boot.iter().take(8).enumerate() {
        info!(idx = i, node = %n, "bootnode sample");
    }
    discv4_cfg.add_boot_nodes(boot).lookup_interval(interval);
    let net_cfg = net_cfg.set_discovery_v4(discv4_cfg.build());

    let mut net_manager = NetworkManager::eth(net_cfg).await.unwrap();

    // The network handle is our entrypoint into the network.
    let net_handle = net_manager.handle().clone();
    let mut events = net_handle.event_listener();
    let mut disc_stream = net_handle.discovery_listener();

    // æ³¨å†Œäº¤æ˜“äº‹ä»¶é€šé“ï¼Œæ¥æ”¶ mempool å¹¿æ’­/è¯·æ±‚
    let (tx_event_tx, mut tx_event_rx) = tokio::sync::mpsc::unbounded_channel::<NetworkTransactionEvent>();
    net_manager.set_transactions(tx_event_tx);

    // NetworkManager is a long running task, let's spawn it
    tokio::spawn(net_manager);
    info!("Looking for Polygon peers...");

    // ç›‘å¬å‘ç°äº‹ä»¶ï¼ˆä»…è®°å½•æ—¥å¿—ï¼Œä¸å†æ‰‹å·¥ç›´è¿å—…æ¢ï¼Œé¿å…ä¸åˆè§„ä¼šè¯è¢«è¿œç«¯æ¸…ç†ï¼‰
    tokio::spawn(async move {
        use reth_ethereum::network::api::events::{DiscoveryEvent, DiscoveredEvent};
        while let Some(evt) = disc_stream.next().await {
            match evt {
                DiscoveryEvent::NewNode(DiscoveredEvent::EventQueued { peer_id, addr, fork_id }) => {
                    info!(%peer_id, addr=?addr, fork=?fork_id, "discovery: queued new node");
                }
                DiscoveryEvent::EnrForkId(peer_id, fork) => {
                    info!(%peer_id, fork=?fork, "discovery: enr forkid");
                }
            }
        }
    });

    // äº¤æ˜“äº‹ä»¶å¤„ç†ï¼ˆç‹¬ç«‹ä»»åŠ¡ï¼Œå¿…é¡»åœ¨äº‹ä»¶å¾ªç¯ä¹‹å‰å¯åŠ¨ï¼‰
    // é‡è¦ï¼šå¯¹æ¯ä¸ªå¹¿æ’­è¯·æ±‚å¹¶å‘å¤„ç†ï¼Œé¿å…é˜»å¡æ¥æ”¶ç«¯å¯¼è‡´ç§¯å‹ï¼Œä»è€Œå¤„ç†åˆ°â€œå¾ˆä¹…ä»¥å‰â€çš„å¹¿æ’­
    let handle_for_tx = net_handle.clone();
    let tx_req_semaphore = std::sync::Arc::new(Semaphore::new(128));
    tokio::spawn(async move {
        use reth_ethereum::network::eth_wire::{GetPooledTransactions, NewPooledTransactionHashes, PooledTransactions};
        use tokio::sync::oneshot;
        while let Some(event) = tx_event_rx.recv().await {
            match event {
                NetworkTransactionEvent::IncomingPooledTransactionHashes { peer_id, msg } => {
                    let hashes: Vec<_> = match msg {
                        NewPooledTransactionHashes::Eth66(h) => h.0,
                        NewPooledTransactionHashes::Eth68(h) => h.hashes,
                    };
                    if !hashes.is_empty() {
                        let permit = tx_req_semaphore.clone().acquire_owned().await;
                        let handle = handle_for_tx.clone();
                        tokio::spawn(async move {
                            let _permit = match permit { Ok(p) => p, Err(_) => return };
                            let request = GetPooledTransactions(hashes.clone());
                            let (resp_tx, resp_rx) = oneshot::channel();
                            let peer_req = PeerRequest::GetPooledTransactions { request, response: resp_tx };
                            handle.send_request(peer_id, peer_req);
                            match tokio::time::timeout(Duration::from_millis(2500), resp_rx).await {
                                Ok(Ok(Ok(PooledTransactions(txs)))) => {
                                    let sample: Vec<String> = hashes.iter().take(8).map(|h| format!("0x{:x}", h)).collect();
                                    info!(peer = %peer_id, hashes = hashes.len(), txs = txs.len(), sample = ?sample, "mempool: fetched txs from hashes broadcast");
                                }
                                Ok(Ok(Err(e))) => {
                                    info!(peer = %peer_id, error = %e, "mempool: peer request failed");
                                }
                                Ok(Err(e)) => {
                                    info!(peer = %peer_id, error = %e, "mempool: response channel closed");
                                }
                                Err(_) => {
                                    info!(peer = %peer_id, "mempool: request timeout (2.5s), drop stale response");
                                }
                            }
                        });
                    }
                }
                NetworkTransactionEvent::IncomingTransactions { peer_id, msg } => {
                    let process_start = Instant::now();
                    let txs = msg.0;
                    let count = txs.len();
                    
                    // æ›´æ–°ç»Ÿè®¡
                    PERF_METRICS.tx_processed.fetch_add(count as u64, Ordering::Relaxed);
                    
                    // å¿«é€Ÿåˆ†æï¼ˆè½»é‡çº§æ“ä½œï¼‰
                    let want1 = alloy_primitives::address!("0x56C79347e95530c01A2FC76E732f9566dA16E113");
                    let want2 = alloy_primitives::address!("0x78769D50Be1763ed1CA0D5E878D93f05aabff29e");
                    
                    let analyses: Vec<_> = measure_blocking!(PERF_METRICS, {
                        txs.iter()
                            .map(|tx| {
                                let to = tx.to();
                                let include = matches!(to, Some(a) if a == want1 || a == want2);
                                analysis::analyze_transaction_filtered(tx, include)
                            })
                            .collect()
                    });
                    
                    let sample: Vec<String> = analyses.iter().take(8).map(|a| format!("0x{:x}", a.hash)).collect();
                    
                    // éé˜»å¡å‘é€åˆ°Redisé˜Ÿåˆ—
                    if let Err(e) = redis_async::store_tx_analysis_async(analyses.clone()) {
                        eprintln!("Failed to queue tx analysis: {}", e);
                    }

                    // ä¼˜åŒ–çš„å¹¶è¡ŒCTFå¤„ç†
                    let metrics_ref = PERF_METRICS.clone();
                    tokio::spawn(async move {
                        let decode_start = Instant::now();
                        
                        // æ”¶é›†éœ€è¦å¤„ç†çš„CTFäº¤æ˜“
                        let ctf_tasks: Vec<_> = analyses
                            .iter()
                            .filter_map(|a| {
                                if let (Some(to), Some(calldata_hex)) = (a.receiver, a.calldata_hex.as_ref()) {
                                    let is_ctf = to == want1 || to == want2;
                                    if is_ctf {
                                        Some((a.clone(), to, calldata_hex.clone()))
                                    } else {
                                        None
                                    }
                                } else {
                                    None
                                }
                            })
                            .collect();
                        
                        // å¹¶è¡Œå¤„ç†æ‰€æœ‰CTFäº¤æ˜“
                        let ctf_futures: Vec<_> = ctf_tasks
                            .into_iter()
                            .map(|(a, to, calldata_hex)| {
                                let metrics_clone = metrics_ref.clone();
                                async move {
                                    let bytes = match calldata_hex.strip_prefix("0x") { 
                                        Some(h) => h, 
                                        None => &calldata_hex 
                                    };
                                    
                                    if let Ok(b) = hex::decode(bytes) {
                                        let decode_start = Instant::now();
                                        let decoded = decode_ctf_like_calldata_fast(to, &b[..]);
                                        let decode_time = decode_start.elapsed().as_nanos() as u64;
                                        
                                        // æ›´æ–°è§£ç æ—¶é—´ç»Ÿè®¡
                                        metrics_clone.avg_decode_time_ns.store(decode_time, Ordering::Relaxed);
                                        
                                        if let Some(decoded_data) = decoded {
                                            let line = serde_json::json!({
                                                "hash": format!("0x{:x}", a.hash),
                                                "to": format!("0x{:x}", to),
                                                "value": format!("{}", a.value),
                                                "gas_limit": a.gas_limit,
                                                "gas_price_or_max_fee": a.gas_price_or_max_fee,
                                                "max_priority_fee": a.max_priority_fee,
                                                "decoded": decoded_data,
                                            }).to_string();
                                            
                                            if let Err(e) = redis_async::store_ctf_tx_async(line) {
                                                eprintln!("Failed to queue CTF tx: {}", e);
                                            }
                                            return Some((1, decode_time));
                                        }
                                    }
                                    None
                                }
                            })
                            .collect();
                        
                        // ç­‰å¾…æ‰€æœ‰CTFå¤„ç†å®Œæˆ
                        let results = futures::future::join_all(ctf_futures).await;
                        let (count, total_time): (u64, u64) = results
                            .into_iter()
                            .filter_map(|x| x)
                            .fold((0, 0), |(acc_count, acc_time), (count, time)| {
                                (acc_count + count, acc_time + time)
                            });
                        
                        let ctf_processed = count;
                        let total_decode_time_sum = total_time;
                        
                        let total_elapsed = decode_start.elapsed().as_nanos() as u64;
                        metrics_ref.ctf_decoded.fetch_add(ctf_processed, Ordering::Relaxed);
                        
                        if ctf_processed > 0 {
                            let avg_decode_time = if ctf_processed > 0 { total_decode_time_sum / ctf_processed } else { 0 };
                            info!("âš¡ CTFæ‰¹å¤„ç†å®Œæˆ: {} ä¸ªäº¤æ˜“, æ€»è€—æ—¶: {}Î¼s, å¹³å‡è§£ç : {}Î¼s", 
                                ctf_processed, 
                                total_elapsed / 1000,
                                avg_decode_time / 1000
                            );
                        }
                    });

                    let total_time = process_start.elapsed();
                    info!(
                        peer = %peer_id, 
                        count, 
                        sample = ?sample, 
                        time_us = total_time.as_micros(),
                        "mempool: æé€Ÿå¤„ç†å®Œæˆ ({}Î¼s)", 
                        total_time.as_micros()
                    );
                }
                NetworkTransactionEvent::GetPooledTransactions { peer_id, request, response } => {
                    // ä»å¯æœ€å°åº”ç­”ï¼Œä½†ä¸ºäº†å‡å°‘é‡å¤è¯·æ±‚ç§¯å‹ï¼Œé™åˆ¶é¢‘ç‡ï¼šè¿‡å¤§æ‰¹æ¬¡ç›´æ¥è¿”å›ç©º
                    if request.0.len() > 512 {
                        let _ = response.send(Ok(PooledTransactions::default()));
                    } else {
                        let _ = response.send(Ok(PooledTransactions::default()));
                    }
                    info!(peer = %peer_id, count = request.0.len(), "mempool: answered GetPooledTransactions (rate-limited)");
                }
                _ => {}
            }
        }
    });

    while let Some(evt) = events.next().await {
        match evt {
            NetworkEvent::ActivePeerSession { info, .. } => {
                let SessionInfo { ref status, ref client_version, .. } = info;
                let chain = status.chain;
                info!(?chain, ?client_version, "Session established with a new peer.");
                persist_session_established(&info);
                // å‘¨æœŸæ€§è½®è¯¢ç§»é™¤ï¼Œæ”¹ä¸ºï¼šæ”¶åˆ°å¹¿æ’­åç”¨ PeerRequest æ‹‰å–ï¼Œé™ä½å†…éƒ¨é€šé“å…³é—­å¯¼è‡´çš„ panic é£é™©
            }
            NetworkEvent::Peer(peer_evt) => {
                match peer_evt {
                    reth_ethereum::network::api::events::PeerEvent::SessionClosed { peer_id, reason } => {
                        info!(%peer_id, ?reason, "Session closed");
                    }
                    reth_ethereum::network::api::events::PeerEvent::SessionEstablished(info) => {
                        info!(peer_id = %info.peer_id, client = %info.client_version, "Peer session established");
                        persist_session_established(&info);
                    }
                    reth_ethereum::network::api::events::PeerEvent::PeerAdded(peer_id) => {
                        info!(%peer_id, "Peer added to the pool");
                    }
                    reth_ethereum::network::api::events::PeerEvent::PeerRemoved(peer_id) => {
                        info!(%peer_id, "Peer removed from the pool");
                    }
                }
            }
        }
    }
    // We will be disconnected from peers since we are not able to answer to network requests
}
